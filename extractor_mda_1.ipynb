{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spikeinterface\n",
      "  Downloading https://files.pythonhosted.org/packages/e4/21/85159512241e384fd1203d2b08d835e76b3ab30190555b215a9730dcee8b/spikeinterface-0.10.0-py3-none-any.whl\n",
      "Collecting spikeextractors>=0.9.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/72/3ff80ad2721fc1d39214bdb56fe41167281dea3170d90ef29dc6c0207980/spikeextractors-0.9.2.tar.gz (95kB)\n",
      "\u001b[K     |████████████████████████████████| 102kB 2.5MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting spikesorters>=0.4.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/5f/364462d9d3ade51ddd858cc63c8b401e73a3519473e858c882512247dad3/spikesorters-0.4.2.tar.gz (49kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 2.5MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting spikecomparison>=0.3.0\n",
      "  Downloading https://files.pythonhosted.org/packages/6e/44/f4b6676247c0cbd47bf83bad711d0de2cfac5d2c2bff92c02cabe76954ff/spikecomparison-0.3.0.tar.gz\n",
      "Collecting spikewidgets>=0.5.0\n",
      "  Downloading https://files.pythonhosted.org/packages/7d/fc/6fc49c7e18b8b23ba0043ca1b1fa93ebbe575a7d580dd32539172c2fe0e6/spikewidgets-0.5.0.tar.gz\n",
      "Collecting spiketoolkit>=0.7.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/62/be5b1a326d25e1adea5154f2abc72cdf4a8f8fef633d8897fcf85480e40a/spiketoolkit-0.7.0.tar.gz (55kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 2.9MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/lib64/python3.8/site-packages (from spikeextractors>=0.9.1->spikeinterface) (1.18.4)\n",
      "Requirement already satisfied: tqdm in /usr/lib/python3.8/site-packages (from spikeextractors>=0.9.1->spikeinterface) (4.47.0)\n",
      "Requirement already satisfied: requests in /usr/lib/python3.8/site-packages (from spikesorters>=0.4.2->spikeinterface) (2.22.0)\n",
      "Requirement already satisfied: scipy in /usr/lib64/python3.8/site-packages (from spikecomparison>=0.3.0->spikeinterface) (1.4.1)\n",
      "Requirement already satisfied: pandas in /usr/lib64/python3.8/site-packages (from spikecomparison>=0.3.0->spikeinterface) (0.25.3)\n",
      "Requirement already satisfied: networkx in /usr/lib/python3.8/site-packages (from spikecomparison>=0.3.0->spikeinterface) (2.5)\n",
      "Requirement already satisfied: joblib in /usr/lib/python3.8/site-packages (from spikecomparison>=0.3.0->spikeinterface) (0.13.2)\n",
      "Requirement already satisfied: matplotlib in /usr/lib64/python3.8/site-packages (from spikewidgets>=0.5.0->spikeinterface) (3.2.2)\n",
      "Collecting MEAutility>=1.4.6\n",
      "  Downloading https://files.pythonhosted.org/packages/f6/f0/4eda4cb3e2b652c178f70aad009ac1a0bb90dc5f15d883c001db3a959a4b/MEAutility-1.4.8.tar.gz\n",
      "Collecting spikemetrics>=0.2.2\n",
      "  Downloading https://files.pythonhosted.org/packages/9c/30/1303e37e76cd679e7fa1b231be805f522cb1d70c53676d76a1fbd823a2e0/spikemetrics-0.2.2.tar.gz\n",
      "Collecting spikefeatures\n",
      "  Downloading https://files.pythonhosted.org/packages/e8/e4/7a49809d7d26c51f951cda5d2775ed3f9a8fce9a0402fce0667ec0cc6753/spikefeatures-0.1.1.tar.gz\n",
      "Requirement already satisfied: scikit-learn in /usr/lib64/python3.8/site-packages (from spiketoolkit>=0.7.0->spikeinterface) (0.22.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/lib/python3.8/site-packages (from requests->spikesorters>=0.4.2->spikeinterface) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/lib/python3.8/site-packages (from requests->spikesorters>=0.4.2->spikeinterface) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/lib/python3.8/site-packages (from requests->spikesorters>=0.4.2->spikeinterface) (1.25.7)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/lib/python3.8/site-packages (from pandas->spikecomparison>=0.3.0->spikeinterface) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/lib/python3.8/site-packages (from pandas->spikecomparison>=0.3.0->spikeinterface) (2020.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/lib/python3.8/site-packages (from networkx->spikecomparison>=0.3.0->spikeinterface) (4.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/lib/python3.8/site-packages (from matplotlib->spikewidgets>=0.5.0->spikeinterface) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/lib64/python3.8/site-packages (from matplotlib->spikewidgets>=0.5.0->spikeinterface) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/lib/python3.8/site-packages (from matplotlib->spikewidgets>=0.5.0->spikeinterface) (2.4.7)\n",
      "Requirement already satisfied: pyyaml in /usr/lib64/python3.8/site-packages (from MEAutility>=1.4.6->spikewidgets>=0.5.0->spikeinterface) (5.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3.8/site-packages (from python-dateutil>=2.6.1->pandas->spikecomparison>=0.3.0->spikeinterface) (1.14.0)\n",
      "Building wheels for collected packages: spikeextractors, spikesorters, spikecomparison, spikewidgets, spiketoolkit, MEAutility, spikemetrics, spikefeatures\n",
      "  Building wheel for spikeextractors (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for spikeextractors: filename=spikeextractors-0.9.2-cp38-none-any.whl size=132862 sha256=f0d66b16d614e50a8dd2164a5621de9da7492a82aa33a3ba4c57171f0a8e6a96\n",
      "  Stored in directory: /home/accts/bsa9/.cache/pip/wheels/a2/79/bc/76c962d300bb7f996e88b0c0a4b1da9322ba09d8b8b5733b05\n",
      "  Building wheel for spikesorters (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for spikesorters: filename=spikesorters-0.4.2-cp38-none-any.whl size=73084 sha256=5a876c300f59fe7f8a742a1ac7491a9f5d8082fc51bae8919711173f81ff93bf\n",
      "  Stored in directory: /home/accts/bsa9/.cache/pip/wheels/12/4d/95/aae47e3c85b3a4f94a029cad26762c498cd16f14deb352162c\n",
      "  Building wheel for spikecomparison (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for spikecomparison: filename=spikecomparison-0.3.0-cp38-none-any.whl size=25983 sha256=239acec63da8f92c3c389cbefaa062bae039d3ffa82cb756ecc5b35b78937ffc\n",
      "  Stored in directory: /home/accts/bsa9/.cache/pip/wheels/aa/af/2b/b9016e19a62dfc920f122257a2e8005caae95d1f36bbdc2f60\n",
      "  Building wheel for spikewidgets (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for spikewidgets: filename=spikewidgets-0.5.0-cp38-none-any.whl size=37921 sha256=b1c7e7f2fb4031ee3567e4b146a179a99d3b072c31ecc8d4e7a417e75e073e6a\n",
      "  Stored in directory: /home/accts/bsa9/.cache/pip/wheels/3b/9e/32/cfc0fb5d9d0a09b66633a2d5dd26db78cf3e277e039b4f448a\n",
      "  Building wheel for spiketoolkit (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for spiketoolkit: filename=spiketoolkit-0.7.0-cp38-none-any.whl size=86510 sha256=70612bc815051f676ea82fb54cefa860c37c37b6deea3bc5e67a04d08b1014ea\n",
      "  Stored in directory: /home/accts/bsa9/.cache/pip/wheels/45/c4/ad/236da71ee8fed5f4e9da636da8bb4c2e2bd3280c4293fcbdcf\n",
      "  Building wheel for MEAutility (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for MEAutility: filename=MEAutility-1.4.8-cp38-none-any.whl size=39069 sha256=551522a93fa5c4d3fecae0af45bf8a02eca7aed5e991e278d1b1a1e8afcfd475\n",
      "  Stored in directory: /home/accts/bsa9/.cache/pip/wheels/ca/49/97/1d1ca0746c97177c062488d43241057771d5d50b5396c4abe6\n",
      "  Building wheel for spikemetrics (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for spikemetrics: filename=spikemetrics-0.2.2-cp38-none-any.whl size=19321 sha256=0a56422e3bb4fe4424495e00ffd27c675aa0d51059bbebe1594159e70814ecee\n",
      "  Stored in directory: /home/accts/bsa9/.cache/pip/wheels/b6/f5/38/bff0376a3d485749c08ec61f3363d5d20bb216b41cddd517a2\n",
      "  Building wheel for spikefeatures (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for spikefeatures: filename=spikefeatures-0.1.1-cp38-none-any.whl size=5815 sha256=827ae7edcd1a4c6abb1a27e4097984024d6287bbc8c7e4fe4e4df7c4c61cd454\n",
      "  Stored in directory: /home/accts/bsa9/.cache/pip/wheels/b3/58/cb/ccd9d1665fa381bdcf27466abe1a4ea0cb96d70f684c53e70f\n",
      "Successfully built spikeextractors spikesorters spikecomparison spikewidgets spiketoolkit MEAutility spikemetrics spikefeatures\n",
      "Installing collected packages: spikeextractors, spikemetrics, spikefeatures, spiketoolkit, spikesorters, spikecomparison, MEAutility, spikewidgets, spikeinterface\n",
      "\u001b[31mERROR: Could not install packages due to an EnvironmentError: [Errno 13] Permission denied: '/usr/local/lib/python3.8'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install spikeinterface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ml_ms4alg\n",
      "  Downloading https://files.pythonhosted.org/packages/58/bf/a3d5133ddcc1c8df304dc684176cd8c434701617dd159baecbf06a6e6ddf/ml_ms4alg-0.3.5.tar.gz\n",
      "Collecting pybind11\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/e3/d576f6f02bc75bacbc3d42494e8f1d063c95617d86648dba243c2cb3963e/pybind11-2.5.0-py2.py3-none-any.whl (296kB)\n",
      "\u001b[K     |████████████████████████████████| 296kB 5.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting isosplit5\n",
      "  Downloading https://files.pythonhosted.org/packages/9d/11/13376e6e28f2442796d1967bd9e46f9686f030f5c41403d825c5ce1a13e3/isosplit5-0.1.3.tar.gz\n",
      "Requirement already satisfied: numpy in /usr/lib64/python3.8/site-packages (from ml_ms4alg) (1.18.4)\n",
      "Collecting mountainlab_pytools\n",
      "  Downloading https://files.pythonhosted.org/packages/5e/23/6dda8efca74b8e011e476de2d8395c325b7ad5e1f75416515757f6db8214/mountainlab_pytools-0.7.5-py3-none-any.whl\n",
      "Requirement already satisfied: h5py in /usr/lib64/python3.8/site-packages (from ml_ms4alg) (2.9.0)\n",
      "Collecting sklearn\n",
      "  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\n",
      "Processing /home/accts/bsa9/.cache/pip/wheels/a2/79/bc/76c962d300bb7f996e88b0c0a4b1da9322ba09d8b8b5733b05/spikeextractors-0.9.2-cp38-none-any.whl\n",
      "Requirement already satisfied: requests in /usr/lib/python3.8/site-packages (from mountainlab_pytools->ml_ms4alg) (2.22.0)\n",
      "Collecting vdom\n",
      "  Downloading https://files.pythonhosted.org/packages/e2/df/d9c893a5d96a7b65a30fd315dbb2899f919a46fb4600ddb9df11b78b971a/vdom-0.6-py3-none-any.whl\n",
      "Requirement already satisfied: ipython in /usr/lib/python3.8/site-packages (from mountainlab_pytools->ml_ms4alg) (7.12.0)\n",
      "Collecting ipywidgets\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/a0/dbcf5881bb2f51e8db678211907f16ea0a182b232c591a6d6f276985ca95/ipywidgets-7.5.1-py2.py3-none-any.whl (121kB)\n",
      "\u001b[K     |████████████████████████████████| 122kB 14.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jp-proxy-widget\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/ef/fc24654d55fabbb7942582e430625f6522b7e9988f54ea30ea42cde192e3/jp_proxy_widget-1.0.7-py2.py3-none-any.whl (1.2MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2MB 13.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpydoc in /usr/lib/python3.8/site-packages (from mountainlab_pytools->ml_ms4alg) (0.9.2)\n",
      "Requirement already satisfied: six in /usr/lib/python3.8/site-packages (from h5py->ml_ms4alg) (1.14.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/lib64/python3.8/site-packages (from sklearn->ml_ms4alg) (0.22.1)\n",
      "Requirement already satisfied: tqdm in /usr/lib/python3.8/site-packages (from spikeextractors>=0.4.1->ml_ms4alg) (4.47.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/lib/python3.8/site-packages (from requests->mountainlab_pytools->ml_ms4alg) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/lib/python3.8/site-packages (from requests->mountainlab_pytools->ml_ms4alg) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/lib/python3.8/site-packages (from requests->mountainlab_pytools->ml_ms4alg) (1.25.7)\n",
      "Requirement already satisfied: jsonschema in /usr/lib/python3.8/site-packages (from vdom->mountainlab_pytools->ml_ms4alg) (3.2.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/lib/python3.8/site-packages (from ipywidgets->mountainlab_pytools->ml_ms4alg) (4.3.3)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /usr/lib/python3.8/site-packages (from ipywidgets->mountainlab_pytools->ml_ms4alg) (5.0.4)\n",
      "Collecting widgetsnbextension~=3.5.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/7b/7ac231c20d2d33c445eaacf8a433f4e22c60677eb9776c7c5262d7ddee2d/widgetsnbextension-3.5.1-py2.py3-none-any.whl (2.2MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2MB 30.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: ipykernel>=4.5.1 in /usr/lib/python3.8/site-packages (from ipywidgets->mountainlab_pytools->ml_ms4alg) (5.1.4)\n",
      "Collecting jupyter-ui-poll\n",
      "  Downloading https://files.pythonhosted.org/packages/fc/4d/f7cb8ea5bad31fa68dfb689c9fa51e0ffa8ed08f4e07c3d3acac005f3506/jupyter_ui_poll-0.1.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: sphinx>=1.6.5 in /usr/lib/python3.8/site-packages (from numpydoc->mountainlab_pytools->ml_ms4alg) (2.2.2)\n",
      "Requirement already satisfied: Jinja2>=2.3 in /usr/lib/python3.8/site-packages (from numpydoc->mountainlab_pytools->ml_ms4alg) (2.11.2)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/lib/python3.8/site-packages (from jsonschema->vdom->mountainlab_pytools->ml_ms4alg) (19.3.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/lib64/python3.8/site-packages (from jsonschema->vdom->mountainlab_pytools->ml_ms4alg) (0.16.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3.8/site-packages (from jsonschema->vdom->mountainlab_pytools->ml_ms4alg) (41.6.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /usr/lib/python3.8/site-packages (from widgetsnbextension~=3.5.0->ipywidgets->mountainlab_pytools->ml_ms4alg) (6.0.2)\n",
      "Requirement already satisfied: jupyter_client in /usr/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets->mountainlab_pytools->ml_ms4alg) (5.3.4)\n",
      "Requirement already satisfied: tornado>=4.2 in /usr/lib64/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets->mountainlab_pytools->ml_ms4alg) (6.0.3)\n",
      "Requirement already satisfied: sphinxcontrib-applehelp in /usr/lib/python3.8/site-packages (from sphinx>=1.6.5->numpydoc->mountainlab_pytools->ml_ms4alg) (1.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp in /usr/lib/python3.8/site-packages (from sphinx>=1.6.5->numpydoc->mountainlab_pytools->ml_ms4alg) (1.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath in /usr/lib/python3.8/site-packages (from sphinx>=1.6.5->numpydoc->mountainlab_pytools->ml_ms4alg) (1.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp in /usr/lib/python3.8/site-packages (from sphinx>=1.6.5->numpydoc->mountainlab_pytools->ml_ms4alg) (1.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/lib/python3.8/site-packages (from sphinx>=1.6.5->numpydoc->mountainlab_pytools->ml_ms4alg) (1.1.3)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp in /usr/lib/python3.8/site-packages (from sphinx>=1.6.5->numpydoc->mountainlab_pytools->ml_ms4alg) (1.0.2)\n",
      "Requirement already satisfied: Pygments>=2.0 in /usr/lib/python3.8/site-packages (from sphinx>=1.6.5->numpydoc->mountainlab_pytools->ml_ms4alg) (2.4.2)\n",
      "Requirement already satisfied: docutils>=0.12 in /usr/lib/python3.8/site-packages (from sphinx>=1.6.5->numpydoc->mountainlab_pytools->ml_ms4alg) (0.15.2)\n",
      "Requirement already satisfied: snowballstemmer>=1.1 in /usr/lib/python3.8/site-packages (from sphinx>=1.6.5->numpydoc->mountainlab_pytools->ml_ms4alg) (1.9.0)\n",
      "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/lib/python3.8/site-packages (from sphinx>=1.6.5->numpydoc->mountainlab_pytools->ml_ms4alg) (2.8.0)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/lib/python3.8/site-packages (from sphinx>=1.6.5->numpydoc->mountainlab_pytools->ml_ms4alg) (0.7.12)\n",
      "Requirement already satisfied: imagesize in /usr/lib/python3.8/site-packages (from sphinx>=1.6.5->numpydoc->mountainlab_pytools->ml_ms4alg) (1.2.0)\n",
      "Requirement already satisfied: packaging in /usr/lib/python3.8/site-packages (from sphinx>=1.6.5->numpydoc->mountainlab_pytools->ml_ms4alg) (20.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/lib64/python3.8/site-packages (from Jinja2>=2.3->numpydoc->mountainlab_pytools->ml_ms4alg) (1.1.1)\n",
      "Requirement already satisfied: pyzmq>=17 in /usr/lib64/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->mountainlab_pytools->ml_ms4alg) (18.1.0)\n",
      "Requirement already satisfied: ipython_genutils in /usr/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->mountainlab_pytools->ml_ms4alg) (0.1.0)\n",
      "Requirement already satisfied: jupyter_core>=4.6.0 in /usr/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->mountainlab_pytools->ml_ms4alg) (4.6.1)\n",
      "Requirement already satisfied: nbconvert in /usr/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->mountainlab_pytools->ml_ms4alg) (5.6.0)\n",
      "Requirement already satisfied: Send2Trash in /usr/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->mountainlab_pytools->ml_ms4alg) (1.4.2)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /usr/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->mountainlab_pytools->ml_ms4alg) (0.8.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: prometheus_client in /usr/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->mountainlab_pytools->ml_ms4alg) (0.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/lib/python3.8/site-packages (from jupyter_client->ipykernel>=4.5.1->ipywidgets->mountainlab_pytools->ml_ms4alg) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2015.7 in /usr/lib/python3.8/site-packages (from babel!=2.0,>=1.3->sphinx>=1.6.5->numpydoc->mountainlab_pytools->ml_ms4alg) (2020.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/lib/python3.8/site-packages (from packaging->sphinx>=1.6.5->numpydoc->mountainlab_pytools->ml_ms4alg) (2.4.7)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/lib64/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->mountainlab_pytools->ml_ms4alg) (0.8.3)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->mountainlab_pytools->ml_ms4alg) (0.3)\n",
      "Requirement already satisfied: bleach in /usr/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->mountainlab_pytools->ml_ms4alg) (3.1.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->mountainlab_pytools->ml_ms4alg) (1.4.1)\n",
      "Requirement already satisfied: testpath in /usr/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->mountainlab_pytools->ml_ms4alg) (0.3.1)\n",
      "Requirement already satisfied: defusedxml in /usr/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->mountainlab_pytools->ml_ms4alg) (0.6.0)\n",
      "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/lib/python3.8/site-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->mountainlab_pytools->ml_ms4alg) (0.6.0)\n",
      "Requirement already satisfied: decorator in /usr/lib/python3.8/site-packages (from prometheus_client->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->mountainlab_pytools->ml_ms4alg) (4.4.0)\n",
      "Requirement already satisfied: webencodings in /usr/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->mountainlab_pytools->ml_ms4alg) (0.5.1)\n",
      "Building wheels for collected packages: ml-ms4alg, isosplit5, sklearn\n",
      "  Building wheel for ml-ms4alg (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ml-ms4alg: filename=ml_ms4alg-0.3.5-cp38-none-any.whl size=16640 sha256=01f88482e63a1ba878ebe48eb0bb253ca79a6106c2ff05639795304bee556865\n",
      "  Stored in directory: /home/accts/bsa9/.cache/pip/wheels/b9/7a/88/ae1a50846ec89beddeb54c1d512dd8fafb492fdfea695c7bf8\n",
      "  Building wheel for isosplit5 (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-egklguie/isosplit5/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-egklguie/isosplit5/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-qmhiqse6 --python-tag cp38\n",
      "       cwd: /tmp/pip-install-egklguie/isosplit5/\n",
      "  Complete output (63 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build/lib.linux-x86_64-3.8\n",
      "  creating build/lib.linux-x86_64-3.8/isosplit5\n",
      "  copying isosplit5/__init__.py -> build/lib.linux-x86_64-3.8/isosplit5\n",
      "  running build_ext\n",
      "  creating tmp\n",
      "  gcc -pthread -Wno-unused-result -Wsign-compare -DDYNAMIC_ANNOTATIONS_ENABLED=1 -DNDEBUG -O2 -g -pipe -Wall -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -Wp,-D_GLIBCXX_ASSERTIONS -fexceptions -fstack-protector-strong -grecord-gcc-switches -m64 -mtune=generic -fasynchronous-unwind-tables -fstack-clash-protection -fcf-protection -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -Wp,-D_GLIBCXX_ASSERTIONS -fexceptions -fstack-protector-strong -grecord-gcc-switches -m64 -mtune=generic -fasynchronous-unwind-tables -fstack-clash-protection -fcf-protection -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -Wp,-D_GLIBCXX_ASSERTIONS -fexceptions -fstack-protector-strong -grecord-gcc-switches -m64 -mtune=generic -fasynchronous-unwind-tables -fstack-clash-protection -fcf-protection -D_GNU_SOURCE -fPIC -fwrapv -fPIC -I/usr/include/python3.8 -c /tmp/tmpfx_f8kno.cpp -o tmp/tmpfx_f8kno.o -std=c++14\n",
      "  gcc -pthread -Wno-unused-result -Wsign-compare -DDYNAMIC_ANNOTATIONS_ENABLED=1 -DNDEBUG -O2 -g -pipe -Wall -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -Wp,-D_GLIBCXX_ASSERTIONS -fexceptions -fstack-protector-strong -grecord-gcc-switches -m64 -mtune=generic -fasynchronous-unwind-tables -fstack-clash-protection -fcf-protection -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -Wp,-D_GLIBCXX_ASSERTIONS -fexceptions -fstack-protector-strong -grecord-gcc-switches -m64 -mtune=generic -fasynchronous-unwind-tables -fstack-clash-protection -fcf-protection -D_GNU_SOURCE -fPIC -fwrapv -O2 -g -pipe -Wall -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -Wp,-D_GLIBCXX_ASSERTIONS -fexceptions -fstack-protector-strong -grecord-gcc-switches -m64 -mtune=generic -fasynchronous-unwind-tables -fstack-clash-protection -fcf-protection -D_GNU_SOURCE -fPIC -fwrapv -fPIC -I/usr/include/python3.8 -c /tmp/tmpxzqqn3cq.cpp -o tmp/tmpxzqqn3cq.o -fvisibility=hidden\n",
      "  building 'isosplit5_interface' extension\n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 1, in <module>\n",
      "    File \"/tmp/pip-install-egklguie/isosplit5/setup.py\", line 88, in <module>\n",
      "      setup(\n",
      "    File \"/usr/lib/python3.8/site-packages/setuptools/__init__.py\", line 145, in setup\n",
      "      return distutils.core.setup(**attrs)\n",
      "    File \"/usr/lib64/python3.8/distutils/core.py\", line 148, in setup\n",
      "      dist.run_commands()\n",
      "    File \"/usr/lib64/python3.8/distutils/dist.py\", line 966, in run_commands\n",
      "      self.run_command(cmd)\n",
      "    File \"/usr/lib64/python3.8/distutils/dist.py\", line 985, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"/usr/lib/python3.8/site-packages/wheel/bdist_wheel.py\", line 192, in run\n",
      "      self.run_command('build')\n",
      "    File \"/usr/lib64/python3.8/distutils/cmd.py\", line 313, in run_command\n",
      "      self.distribution.run_command(command)\n",
      "    File \"/usr/lib64/python3.8/distutils/dist.py\", line 985, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"/usr/lib64/python3.8/distutils/command/build.py\", line 135, in run\n",
      "      self.run_command(cmd_name)\n",
      "    File \"/usr/lib64/python3.8/distutils/cmd.py\", line 313, in run_command\n",
      "      self.distribution.run_command(command)\n",
      "    File \"/usr/lib64/python3.8/distutils/dist.py\", line 985, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"/usr/lib/python3.8/site-packages/setuptools/command/build_ext.py\", line 84, in run\n",
      "      _build_ext.run(self)\n",
      "    File \"/usr/lib64/python3.8/site-packages/Cython/Distutils/old_build_ext.py\", line 186, in run\n",
      "      _build_ext.build_ext.run(self)\n",
      "    File \"/usr/lib64/python3.8/distutils/command/build_ext.py\", line 340, in run\n",
      "      self.build_extensions()\n",
      "    File \"/tmp/pip-install-egklguie/isosplit5/setup.py\", line 83, in build_extensions\n",
      "      build_ext.build_extensions(self)\n",
      "    File \"/usr/lib64/python3.8/site-packages/Cython/Distutils/old_build_ext.py\", line 195, in build_extensions\n",
      "      _build_ext.build_ext.build_extensions(self)\n",
      "    File \"/usr/lib64/python3.8/distutils/command/build_ext.py\", line 449, in build_extensions\n",
      "      self._build_extensions_serial()\n",
      "    File \"/usr/lib64/python3.8/distutils/command/build_ext.py\", line 474, in _build_extensions_serial\n",
      "      self.build_extension(ext)\n",
      "    File \"/usr/lib/python3.8/site-packages/setuptools/command/build_ext.py\", line 205, in build_extension\n",
      "      _build_ext.build_extension(self, ext)\n",
      "    File \"/usr/lib64/python3.8/distutils/command/build_ext.py\", line 528, in build_extension\n",
      "      objects = self.compiler.compile(sources,\n",
      "    File \"/usr/lib64/python3.8/distutils/ccompiler.py\", line 565, in compile\n",
      "      self._setup_compile(output_dir, macros, include_dirs, sources,\n",
      "    File \"/usr/lib64/python3.8/distutils/ccompiler.py\", line 341, in _setup_compile\n",
      "      pp_opts = gen_preprocess_options(macros, incdirs)\n",
      "    File \"/usr/lib64/python3.8/distutils/ccompiler.py\", line 1076, in gen_preprocess_options\n",
      "      pp_opts.append(\"-I%s\" % dir)\n",
      "    File \"/tmp/pip-install-egklguie/isosplit5/setup.py\", line 15, in __str__\n",
      "      import pybind11\n",
      "  ModuleNotFoundError: No module named 'pybind11'\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[31m  ERROR: Failed building wheel for isosplit5\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for isosplit5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1316 sha256=89b0514ba9bfc5bcd7fe6719fcf5a18206e9a2933c2bb19ab774dcd0c81e21e1\n",
      "  Stored in directory: /home/accts/bsa9/.cache/pip/wheels/76/03/bb/589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\n",
      "Successfully built ml-ms4alg sklearn\n",
      "Failed to build isosplit5\n",
      "Installing collected packages: pybind11, isosplit5, vdom, widgetsnbextension, ipywidgets, jupyter-ui-poll, jp-proxy-widget, mountainlab-pytools, sklearn, spikeextractors, ml-ms4alg\n",
      "\u001b[31mERROR: Could not install packages due to an EnvironmentError: [Errno 13] Permission denied: '/usr/local/lib/python3.8'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ml_ms4alg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spikeinterface.extractors as se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = 7\n",
    "sampling_frequency = 30000  # in Hz\n",
    "duration = 20\n",
    "num_timepoints = int(sampling_frequency * duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = np.random.normal(0, 10, (num_channels, num_timepoints))\n",
    "geom = np.zeros((num_channels, 2))\n",
    "geom[:, 0] = range(num_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording = se.NumpyRecordingExtractor(timeseries=timeseries, geom=geom, sampling_frequency=sampling_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. channels = 7\n",
      "Sampling frequency = 30000.0 Hz\n",
      "Num. timepoints = 600000\n",
      "Stdev. on third channel = 10.003604355943711\n",
      "Location of third electrode = [2. 0.]\n"
     ]
    }
   ],
   "source": [
    "print('Num. channels = {}'.format(len(recording.get_channel_ids())))\n",
    "print('Sampling frequency = {} Hz'.format(recording.get_sampling_frequency()))\n",
    "print('Num. timepoints = {}'.format(recording.get_num_frames()))\n",
    "print('Stdev. on third channel = {}'.format(np.std(recording.get_traces(channel_ids=2))))\n",
    "print('Location of third electrode = {}'.format(recording.get_channel_property(channel_id=2, property_name='location')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "se.MdaRecordingExtractor.write_recording(recording=recording, save_path='sample_mountainsort_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class NumpyRecordingExtractor in module spikeextractors.extractors.numpyextractors.numpyextractors:\n",
      "\n",
      "class NumpyRecordingExtractor(spikeextractors.recordingextractor.RecordingExtractor)\n",
      " |  NumpyRecordingExtractor(timeseries, sampling_frequency, geom=None)\n",
      " |  \n",
      " |  A class that contains functions for extracting important information\n",
      " |  from recorded extracellular data. It is an abstract class so all\n",
      " |  functions with the @abstractmethod tag must be implemented for the\n",
      " |  initialization to work.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      NumpyRecordingExtractor\n",
      " |      spikeextractors.recordingextractor.RecordingExtractor\n",
      " |      abc.ABC\n",
      " |      spikeextractors.baseextractor.BaseExtractor\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, timeseries, sampling_frequency, geom=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  get_channel_ids(self)\n",
      " |      Returns the list of channel ids. If not specified, the range from 0 to num_channels - 1 is returned.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      channel_ids: list\n",
      " |          Channel list\n",
      " |  \n",
      " |  get_num_frames(self)\n",
      " |      This function returns the number of frames in the recording\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      num_frames: int\n",
      " |          Number of frames in the recording (duration of recording)\n",
      " |  \n",
      " |  get_sampling_frequency(self)\n",
      " |      This function returns the sampling frequency in units of Hz.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      fs: float\n",
      " |          Sampling frequency of the recordings in Hz\n",
      " |  \n",
      " |  get_traces(self, channel_ids=None, start_frame=None, end_frame=None)\n",
      " |      This function extracts and returns a trace from the recorded data from the\n",
      " |      given channels ids and the given start and end frame. It will return\n",
      " |      traces from within three ranges:\n",
      " |      \n",
      " |          [start_frame, start_frame+1, ..., end_frame-1]\n",
      " |          [start_frame, start_frame+1, ..., final_recording_frame - 1]\n",
      " |          [0, 1, ..., end_frame-1]\n",
      " |          [0, 1, ..., final_recording_frame - 1]\n",
      " |      \n",
      " |      if both start_frame and end_frame are given, if only start_frame is\n",
      " |      given, if only end_frame is given, or if neither start_frame or end_frame\n",
      " |      are given, respectively. Traces are returned in a 2D array that\n",
      " |      contains all of the traces from each channel with dimensions\n",
      " |      (num_channels x num_frames). In this implementation, start_frame is inclusive\n",
      " |      and end_frame is exclusive conforming to numpy standards.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      start_frame: int\n",
      " |          The starting frame of the trace to be returned (inclusive)\n",
      " |      end_frame: int\n",
      " |          The ending frame of the trace to be returned (exclusive)\n",
      " |      channel_ids: array_like\n",
      " |          A list or 1D array of channel ids (ints) from which each trace will be\n",
      " |          extracted\n",
      " |      \n",
      " |      Returns\n",
      " |      ----------\n",
      " |      traces: numpy.ndarray\n",
      " |          A 2D array that contains all of the traces from each channel.\n",
      " |          Dimensions are: (num_channels x num_frames)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  write_recording(recording, save_path)\n",
      " |      This function writes out the recorded file of a given recording\n",
      " |      extractor to the file format of this current recording extractor. Allows\n",
      " |      for easy conversion between recording file formats. It is a static\n",
      " |      method so it can be used without instantiating this recording extractor.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      recording: RecordingExtractor\n",
      " |          An RecordingExtractor that can extract information from the recording\n",
      " |          file to be converted to the new format.\n",
      " |      \n",
      " |      save_path: string\n",
      " |          A path to where the converted recorded data will be saved, which may\n",
      " |          either be a file or a folder, depending on the format.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  extractor_name = 'NumpyRecordingExtractor'\n",
      " |  \n",
      " |  is_writable = True\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from spikeextractors.recordingextractor.RecordingExtractor:\n",
      " |  \n",
      " |  add_epoch(self, epoch_name, start_frame, end_frame)\n",
      " |      This function adds an epoch to your recording extractor that tracks\n",
      " |      a certain time period in your recording. It is stored in an internal\n",
      " |      dictionary of start and end frame tuples.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      epoch_name: str\n",
      " |          The name of the epoch to be added\n",
      " |      start_frame: int\n",
      " |          The start frame of the epoch to be added (inclusive)\n",
      " |      end_frame: int\n",
      " |          The end frame of the epoch to be added (exclusive). If set to None, it will include the entire\n",
      " |          recording after the start_frame\n",
      " |  \n",
      " |  clear_channel_property(self, channel_id, property_name)\n",
      " |      This function clears the channel property for the given property.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      channel_id: int\n",
      " |          The id that specifies a channel in the recording\n",
      " |      property_name: string\n",
      " |          The name of the property to be cleared\n",
      " |  \n",
      " |  clear_channels_property(self, property_name, channel_ids=None)\n",
      " |      This function clears the channels' properties for the given property.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      property_name: string\n",
      " |          The name of the property to be cleared\n",
      " |      channel_ids: list\n",
      " |          A list of ids that specifies a set of channels in the recording. If None all channels ar cleared\n",
      " |  \n",
      " |  copy_channel_properties(self, recording, channel_ids=None)\n",
      " |      Copy channel properties from another recording extractor to the current\n",
      " |      recording extractor.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      recording: RecordingExtractor\n",
      " |          The recording extractor from which the properties will be copied\n",
      " |      channel_ids: (array_like, int)\n",
      " |          The list (or single value) of channel_ids for which the properties will be copied\n",
      " |  \n",
      " |  frame_to_time(self, frame)\n",
      " |      This function converts a user-inputted frame index to a time with units of seconds.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      frame: float\n",
      " |          The frame to be converted to a time\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      time: float\n",
      " |          The corresponding time in seconds\n",
      " |  \n",
      " |  get_channel_gains(self, channel_ids=None)\n",
      " |      This function returns the gain of each channel specifed by\n",
      " |      channel_ids.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      channel_ids: array_like\n",
      " |          The channel ids (ints) for which the gains will be returned\n",
      " |      \n",
      " |      Returns\n",
      " |      ----------\n",
      " |      gains: array_like\n",
      " |          Returns a list of corresonding gains (floats) for the given\n",
      " |          channel_ids\n",
      " |  \n",
      " |  get_channel_groups(self, channel_ids=None)\n",
      " |      This function returns the group of each channel specifed by\n",
      " |      channel_ids\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      channel_ids: array-like or int\n",
      " |          The channel ids (ints) for which the groups will be returned\n",
      " |      \n",
      " |      Returns\n",
      " |      ----------\n",
      " |      groups: array_like\n",
      " |          Returns a list of corresonding groups (ints) for the given\n",
      " |          channel_ids\n",
      " |  \n",
      " |  get_channel_locations(self, channel_ids=None, locations_2d=True)\n",
      " |      This function returns the location of each channel specifed by\n",
      " |      channel_ids\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      channel_ids: array-like or int\n",
      " |          The channel ids (ints) for which the locations will be returned\n",
      " |      locations_2s: bool\n",
      " |          If True (default), first two dimensions are returned\n",
      " |      \n",
      " |      Returns\n",
      " |      ----------\n",
      " |      locations: array_like\n",
      " |          Returns a list of corresponding locations (floats) for the given\n",
      " |          channel_ids\n",
      " |  \n",
      " |  get_channel_property(self, channel_id, property_name)\n",
      " |      This function returns the data stored under the property name from\n",
      " |      the given channel.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      channel_id: int\n",
      " |          The channel id for which the property will be returned\n",
      " |      property_name: str\n",
      " |          A property stored by the RecordingExtractor (location, etc.)\n",
      " |      \n",
      " |      Returns\n",
      " |      ----------\n",
      " |      property_data\n",
      " |          The data associated with the given property name. Could be many\n",
      " |          formats as specified by the user\n",
      " |  \n",
      " |  get_channel_property_names(self, channel_id)\n",
      " |      Get a list of property names for a given channel.\n",
      " |       Parameters\n",
      " |      ----------\n",
      " |      channel_id: int\n",
      " |          The channel id for which the property names will be returned\n",
      " |          If None (default), will return property names for all channels\n",
      " |      Returns\n",
      " |      ----------\n",
      " |      property_names\n",
      " |          The list of property names\n",
      " |  \n",
      " |  get_dtype(self)\n",
      " |  \n",
      " |  get_epoch(self, epoch_name)\n",
      " |      This function returns a SubRecordingExtractor which is a view to the\n",
      " |      given epoch\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      epoch_name: str\n",
      " |          The name of the epoch to be returned\n",
      " |      \n",
      " |      Returns\n",
      " |      ----------\n",
      " |      epoch_extractor: SubRecordingExtractor\n",
      " |          A SubRecordingExtractor which is a view to the given epoch\n",
      " |  \n",
      " |  get_epoch_info(self, epoch_name)\n",
      " |      This function returns the start frame and end frame of the epoch\n",
      " |      in a dict.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      epoch_name: str\n",
      " |          The name of the epoch to be returned\n",
      " |      \n",
      " |      Returns\n",
      " |      ----------\n",
      " |      epoch_info: dict\n",
      " |          A dict containing the start frame and end frame of the epoch\n",
      " |  \n",
      " |  get_epoch_names(self)\n",
      " |      This function returns a list of all the epoch names in your recording\n",
      " |      \n",
      " |      Returns\n",
      " |      ----------\n",
      " |      epoch_names: list\n",
      " |          List of epoch names in the recording extractor\n",
      " |  \n",
      " |  get_num_channels(self)\n",
      " |      This function returns the number of channels in the recording.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      num_channels: int\n",
      " |          Number of channels in the recording\n",
      " |  \n",
      " |  get_shared_channel_property_names(self, channel_ids=None)\n",
      " |      Get the intersection of channel property names for a given set of channels or for all channels if channel_ids is None.\n",
      " |       Parameters\n",
      " |      ----------\n",
      " |      channel_ids: array_like\n",
      " |          The channel ids for which the shared property names will be returned.\n",
      " |          If None (default), will return shared property names for all channels\n",
      " |      Returns\n",
      " |      ----------\n",
      " |      property_names\n",
      " |          The list of shared property names\n",
      " |  \n",
      " |  get_snippets(self, reference_frames, snippet_len, channel_ids=None)\n",
      " |      This function returns data snippets from the given channels that\n",
      " |      are starting on the given frames and are the length of the given snippet\n",
      " |      lengths before and after.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      snippet_len: int or tuple\n",
      " |          If int, the snippet will be centered at the reference frame and\n",
      " |          and return half before and half after of the length. If tuple,\n",
      " |          it will return the first value of before frames and the second value\n",
      " |          of after frames around the reference frame (allows for asymmetry)\n",
      " |      reference_frames: array_like\n",
      " |          A list or array of frames that will be used as the reference frame of\n",
      " |          each snippet\n",
      " |      channel_ids: array_like\n",
      " |          A list or array of channel ids (ints) from which each trace will be\n",
      " |          extracted\n",
      " |      \n",
      " |      Returns\n",
      " |      ----------\n",
      " |      snippets: numpy.ndarray\n",
      " |          Returns a list of the snippets as numpy arrays.\n",
      " |          The length of the list is len(reference_frames)\n",
      " |          Each array has dimensions: (num_channels x snippet_len)\n",
      " |          Out-of-bounds cases should be handled by filling in zeros in the snippet\n",
      " |  \n",
      " |  get_sub_extractors_by_property(self, property_name, return_property_list=False)\n",
      " |      Returns a list of SubRecordingExtractors from this RecordingExtractor based on the given\n",
      " |      property_name (e.g. group)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      property_name: str\n",
      " |          The property used to subdivide the extractor\n",
      " |      return_property_list: bool\n",
      " |          If True the property list is returned\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      sub_list: list\n",
      " |          The list of subextractors to be returned\n",
      " |      OR\n",
      " |      sub_list, prop_list\n",
      " |          If return_property_list is True, the property list will be returned as well\n",
      " |  \n",
      " |  load_probe_file(self, probe_file, channel_map=None, channel_groups=None, verbose=False)\n",
      " |      This function returns a SubRecordingExtractor that contains information from the given\n",
      " |      probe file (channel locations, groups, etc.) If a .prb file is given, then 'location' and 'group'\n",
      " |      information for each channel is added to the SubRecordingExtractor. If a .csv file is given, then\n",
      " |      it will only add 'location' to the SubRecordingExtractor.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      recording: RecordingExtractor\n",
      " |          The recording extractor to channel information\n",
      " |      probe_file: str\n",
      " |          Path to probe file. Either .prb or .csv\n",
      " |      verbose: bool\n",
      " |          If True, output is verbose\n",
      " |      \n",
      " |      Returns\n",
      " |      ---------\n",
      " |      subrecording = SubRecordingExtractor\n",
      " |          The extractor containing all of the probe information.\n",
      " |  \n",
      " |  remove_epoch(self, epoch_name)\n",
      " |      This function removes an epoch from your recording extractor.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      epoch_name: str\n",
      " |          The name of the epoch to be removed\n",
      " |  \n",
      " |  save_to_probe_file(self, probe_file, grouping_property=None, radius=None, graph=True, geometry=True, verbose=False)\n",
      " |      Saves probe file from the channel information of this recording extractor.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      probe_file: str\n",
      " |          file name of .prb or .csv file to save probe information to\n",
      " |      grouping_property: str (default None)\n",
      " |          If grouping_property is a shared_channel_property, different groups are saved based on the property.\n",
      " |      radius: float (default None)\n",
      " |          Adjacency radius (used by some sorters). If None it is not saved to the probe file.\n",
      " |      graph: bool\n",
      " |          If True, the adjacency graph is saved (default=True)\n",
      " |      geometry: bool\n",
      " |          If True, the geometry is saved (default=True)\n",
      " |      verbose: bool\n",
      " |          If True, output is verbose\n",
      " |  \n",
      " |  set_channel_gains(self, channel_ids, gains)\n",
      " |      This function sets the gain property of each specified channel\n",
      " |      id with the corresponding group of the passed in gains float/list.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      channel_ids: array_like\n",
      " |          The channel ids (ints) for which the groups will be specified\n",
      " |      gains: float/array_like\n",
      " |          If a float, each channel will be assigned the corresponding gain.\n",
      " |          If a list, each channel will be given a gain from the list\n",
      " |  \n",
      " |  set_channel_groups(self, groups, channel_ids=None)\n",
      " |      This function sets the group property of each specified channel\n",
      " |      id with the corresponding group of the passed in groups list.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      groups: array-like or int\n",
      " |          A list of groups (ints) for the channel_ids\n",
      " |      channel_ids: array_like or None\n",
      " |          The channel ids (ints) for which the groups will be specified. If None, all channel ids are assumed\n",
      " |  \n",
      " |  set_channel_locations(self, locations, channel_ids=None)\n",
      " |      This function sets the location properties of each specified channel\n",
      " |      id with the corresponding locations of the passed in locations list.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      channel_ids: array-like or int\n",
      " |          The channel ids (ints) for which the locations will be specified\n",
      " |      locations: array_like\n",
      " |          A list of corresponding locations (array_like) for the given channel_ids\n",
      " |  \n",
      " |  set_channel_property(self, channel_id, property_name, value)\n",
      " |      This function adds a property dataset to the given channel under the\n",
      " |      property name.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      channel_id: int\n",
      " |          The channel id for which the property will be added\n",
      " |      property_name: str\n",
      " |          A property stored by the RecordingExtractor (location, etc.)\n",
      " |      value:\n",
      " |          The data associated with the given property name. Could be many\n",
      " |          formats as specified by the user\n",
      " |  \n",
      " |  time_to_frame(self, time)\n",
      " |      This function converts a user-inputted time (in seconds) to a frame index.\n",
      " |      \n",
      " |      Parameters\n",
      " |      -------\n",
      " |      time: float\n",
      " |          The time (in seconds) to be converted to frame index\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      frame: float\n",
      " |          The corresponding frame index\n",
      " |  \n",
      " |  write_to_binary_dat_format(self, save_path, time_axis=0, dtype=None, chunk_size=None, chunk_mb=500, verbose=False)\n",
      " |      Saves the traces of this recording extractor into binary .dat format.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      save_path: str\n",
      " |          The path to the file.\n",
      " |      time_axis: 0 (default) or 1\n",
      " |          If 0 then traces are transposed to ensure (nb_sample, nb_channel) in the file.\n",
      " |          If 1, the traces shape (nb_channel, nb_sample) is kept in the file.\n",
      " |      dtype: dtype\n",
      " |          Type of the saved data. Default float32\n",
      " |      chunk_size: None or int\n",
      " |          If not None then the file is saved in chunks.\n",
      " |          This avoid to much memory consumption for big files.\n",
      " |          If 'auto' the file is saved in chunks of ~ 500Mb\n",
      " |      chunk_mb: None or int\n",
      " |          Chunk size in Mb (default 500Mb)\n",
      " |      verbose: bool\n",
      " |          If True, output is verbose (when chunks are used)\n",
      " |  \n",
      " |  write_to_h5_dataset_format(self, dataset_path, save_path=None, file_handle=None, time_axis=0, dtype=None, chunk_size=None, chunk_mb=500, verbose=False)\n",
      " |      Saves the traces of a recording extractor in an h5 dataset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      recording: RecordingExtractor\n",
      " |          The recording extractor object to be saved in .dat format\n",
      " |      dataset_path: str\n",
      " |          Path to dataset in h5 file (e.g. '/dataset')\n",
      " |      save_path: str\n",
      " |          The path to the file.\n",
      " |      file_handle: file handle\n",
      " |          The file handle to dump data. This can be used to append data to an header. In case file_handle is given,\n",
      " |          the file is NOT closed after writing the binary data.\n",
      " |      time_axis: 0 (default) or 1\n",
      " |          If 0 then traces are transposed to ensure (nb_sample, nb_channel) in the file.\n",
      " |          If 1, the traces shape (nb_channel, nb_sample) is kept in the file.\n",
      " |      dtype: dtype\n",
      " |          Type of the saved data. Default float32.\n",
      " |      chunk_size: None or int\n",
      " |          Number of chunks to save the file in. This avoid to much memory consumption for big files.\n",
      " |          If None and 'chunk_mb' is given, the file is saved in chunks of 'chunk_mb' Mb (default 500Mb)\n",
      " |      chunk_mb: None or int\n",
      " |          Chunk size in Mb (default 500Mb)\n",
      " |      verbose: bool\n",
      " |          If True, output is verbose (when chunks are used)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from spikeextractors.recordingextractor.RecordingExtractor:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from spikeextractors.baseextractor.BaseExtractor:\n",
      " |  \n",
      " |  __del__(self)\n",
      " |  \n",
      " |  allocate_array(self, memmap, shape=None, dtype=None, name=None, array=None)\n",
      " |      Allocates a memory or memmap array\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      memmap: bool\n",
      " |          If True, a memmap array is created in the sorting temporary folder\n",
      " |      shape: tuple\n",
      " |          Shape of the array. If None array must be given\n",
      " |      dtype: dtype\n",
      " |          Dtype of the array. If None array must be given\n",
      " |      name: str or None\n",
      " |          Name (root) of the file (if memmap is True). If None, a random name is generated\n",
      " |      array: np.array\n",
      " |          If array is given, shape and dtype are initialized based on the array. If memmap is True, the array is then\n",
      " |          deleted to clear memory\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      arr: np.array or np.memmap\n",
      " |          The allocated memory or memmap array\n",
      " |  \n",
      " |  check_if_dumpable(self)\n",
      " |  \n",
      " |  dump_to_dict(self)\n",
      " |      Dumps recording to a dictionary.\n",
      " |      The dictionary be used to re-initialize an\n",
      " |      extractor with spikeextractors.load_extractor_from_dict(dump_dict)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dump_dict: dict\n",
      " |          Serialized dictionary\n",
      " |  \n",
      " |  dump_to_json(self, file_path=None)\n",
      " |      Dumps recording extractor to json file.\n",
      " |      The extractor can be re-loaded with spikeextractors.load_extractor_from_json(json_file)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      file_path: str\n",
      " |          Path of the json file\n",
      " |  \n",
      " |  dump_to_pickle(self, file_path=None, include_properties=True, include_features=True)\n",
      " |      Dumps recording extractor to a pickle file.\n",
      " |      The extractor can be re-loaded with spikeextractors.load_extractor_from_json(json_file)\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      file_path: str\n",
      " |          Path of the json file\n",
      " |      include_properties: bool\n",
      " |          If True, all properties are dumped\n",
      " |      include_features: bool\n",
      " |          If True, all features are dumped\n",
      " |  \n",
      " |  get_tmp_folder(self)\n",
      " |      Returns temporary folder associated to the extractor\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      temp_folder: Path\n",
      " |          The temporary folder\n",
      " |  \n",
      " |  make_serialized_dict(self)\n",
      " |      Makes a nested serialized dictionary out of the extractor. The dictionary be used to re-initialize an\n",
      " |      extractor with spikeextractors.load_extractor_from_dict(dump_dict)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dump_dict: dict\n",
      " |          Serialized dictionary\n",
      " |  \n",
      " |  set_tmp_folder(self, folder)\n",
      " |      Sets temporary folder of the extractor\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      folder: str or Path\n",
      " |          The temporary folder\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from spikeextractors.baseextractor.BaseExtractor:\n",
      " |  \n",
      " |  load_extractor_from_dict(d)\n",
      " |      Instantiates extractor from dictionary\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      d: dictionary\n",
      " |          Python dictionary\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      extractor: RecordingExtractor or SortingExtractor\n",
      " |          The loaded extractor object\n",
      " |  \n",
      " |  load_extractor_from_json(json_file)\n",
      " |      Instantiates extractor from json file\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      json_file: str or Path\n",
      " |          Path to json file\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      extractor: RecordingExtractor or SortingExtractor\n",
      " |          The loaded extractor object\n",
      " |  \n",
      " |  load_extractor_from_pickle(pkl_file)\n",
      " |      Instantiates extractor from json file\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      json_file: str or Path\n",
      " |          Path to json file\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      extractor: RecordingExtractor or SortingExtractor\n",
      " |          The loaded extractor object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "help(se.NumpyRecordingExtractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"WindowsPath\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-1df2ef813dfd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrecording2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMdaRecordingExtractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'dataset_1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\spikeextractors\\extractors\\mdaextractors\\mdaextractors.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, folder_path, raw_fname, params_fname, geom_fname)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_directory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_directory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mtimeseries0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_directory\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mraw_fname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_dataset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_directory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams_fname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampling_frequency\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'samplerate'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeseries_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeseries0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\spikeextractors\\extractors\\mdaextractors\\mdaextractors.py\u001b[0m in \u001b[0;36mread_dataset_params\u001b[1;34m(dsdir, params_fname)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[0mfname1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdsdir\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mparams_fname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 236\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Dataset parameter file does not exist: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfname1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"WindowsPath\") to str"
     ]
    }
   ],
   "source": [
    "recording2 = se.MdaRecordingExtractor(folder_path='dataset_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
